{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Pesudocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if not \"..\" in sys.path:\n",
    "    sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from lit_modules.litdatamodules.lit_lamem import LitLaMemDataModule\n",
    "from datasets.LaMem.LaMemDataset import LaMem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "start = time()\n",
    "root = \"/home/soroush1/projects/def-kohitij/soroush1/pretrain-imagenet/data/LaMem/lamem_images/lamem\"\n",
    "\n",
    "data = LitLaMemDataModule(\n",
    "    root=root, num_workers=1, batch_size=128, dev_mode=False, desired_image_size=224\n",
    ")\n",
    "data.setup(\"train\")\n",
    "\n",
    "train_dl = data.train_dataloader()\n",
    "x, y = next(iter(train_dl))\n",
    "\n",
    "print(f\"{abs(start - time())}\")\n",
    "print(f\"{x.size() = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del data, train_dl, x, y\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToPILImage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Select 20 random images and their scores\n",
    "indices = torch.randperm(len(x))[:20]\n",
    "selected_images = x[indices]\n",
    "selected_scores = y[indices]\n",
    "\n",
    "# Convert images to PIL images for plotting\n",
    "to_pil = ToPILImage()\n",
    "\n",
    "# Plotting the images with memorability scores as titles\n",
    "fig, axes = plt.subplots(4, 5, figsize=(20, 16))  # Adjust the size as needed\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, (img, score) in enumerate(zip(selected_images, selected_scores)):\n",
    "    img = to_pil(img)  # Convert to PIL for display\n",
    "    axes[i].imshow(np.asarray(img))\n",
    "    axes[i].set_title(f\"Memorability Score = {score:.2f}\")\n",
    "    axes[i].axis(\"off\")  # Hide axes\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lit_modules.litmodels.lit_vgg import VGGRegression\n",
    "\n",
    "from lit_modules.litmodels.lit_resnet import LitResNet50\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "model = LitResNet50(learning_rate=1e-4)\n",
    "\n",
    "# Example input tensor (batch size, channels, height, width)\n",
    "input_tensor = torch.randn(8, 3, 224, 224)\n",
    "\n",
    "# Get the regression output\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "root = \"/home/soroush1/projects/def-kohitij/soroush1/pretrain-imagenet/data/LaMem/lamem_images/lamem/\"\n",
    "\n",
    "data = LitLaMemDataModule(root=root, num_workers=1, batch_size=32, dev_mode=True)\n",
    "data.setup(\"train\")\n",
    "\n",
    "train_dl = data.train_dataloader()\n",
    "x, y = next(iter(train_dl))\n",
    "\n",
    "\n",
    "model = VGGRegression(output_dim=1)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "for x, y in tqdm(train_dl):\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    output = model(x)\n",
    "    \n",
    "    loss = F.mse_loss(output.squeeze(), y)\n",
    "    \n",
    "    print(f\"{loss = }\")\n",
    "\n",
    "del x, y, data, train_dl\n",
    "del model\n",
    "\n",
    "import gc\n",
    "\n",
    "# Clear GPU cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Collect garbage\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if not \"..\" in sys.path:\n",
    "    sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from lit_modules.litdatamodules.lit_lamem import LitLaMemDataModule\n",
    "from lit_modules.litmodels.lit_vgg_19 import LitVGG19\n",
    "\n",
    "\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import DeviceStatsMonitor, StochasticWeightAveraging\n",
    "\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "from lightning import Trainer\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments \n",
    "\n",
    "- Version0\n",
    "- Version1\n",
    "- Version2\n",
    "    - Experiment:\n",
    "        - First Run on LaMem Dataset\n",
    "        - Finding the Batch size\n",
    "        - Finding the Learning Rate\n",
    "    - Result:\n",
    "        - Batch size = 96\n",
    "        - LR = 1e-4\n",
    "\n",
    "- Version7\n",
    "    - Experiment:\n",
    "        - First Run on LaMem Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/LaMem/lamem_images/lamem/\"\n",
    "datamodule = LitLaMemDataModule(\n",
    "    root=data_path, batch_size=128, num_workers=3, dev_mode=False\n",
    ")\n",
    "tb_logger = TensorBoardLogger(\"./vgg19_lalem\")\n",
    "\n",
    "# 8.317637711026709e-05\n",
    "model = LitVGG19(learning_rate=8.317637711026709e-05)\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=500,\n",
    "    callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10)],\n",
    "    fast_dev_run=False,\n",
    "    devices=\"auto\",\n",
    "    accelerator=\"gpu\",\n",
    "    num_nodes=1,\n",
    "    strategy=\"auto\",\n",
    "    # overfit_batches=0.1,\n",
    "    gradient_clip_val=0.5,\n",
    "    logger=tb_logger,\n",
    "    profiler=\"simple\",\n",
    "    # check_val_every_n_epoch = 1,\n",
    "    # log_every_n_steps=1\n",
    ")\n",
    "\n",
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre06/project/6067616/soroush1/pretrain-imagenet/.venv/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /lustre06/project/6067616/soroush1/pretrain-imagenet ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/lustre06/project/6067616/soroush1/pretrain-imagenet/.venv/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /lustre06/project/6067616/soroush1/pretrain-imagenet ...\n",
      "You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195ff390dfcd4fbc93fc50abb46b5c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 1.2022644346174132e-06\n",
      "Restoring states from the checkpoint path at /lustre06/project/6067616/soroush1/pretrain-imagenet/notebook/.lr_find_8746032a-35ad-4fff-9f55-55dbd353d6f2.ckpt\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/LaMem/lamem_images/lamem/\"\n",
    "datamodule = LitLaMemDataModule(\n",
    "    root=data_path, batch_size=128, num_workers=2, dev_mode=False\n",
    ")\n",
    "tb_logger = TensorBoardLogger(\"./vgg19_lalem\")\n",
    "\n",
    "model = LitVGG19(learning_rate=0.01)\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=200,\n",
    "    # callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10)],\n",
    "    callbacks=[StochasticWeightAveraging(swa_lrs=1e-2)],\n",
    "    fast_dev_run=False,\n",
    "    devices=\"auto\",\n",
    "    accelerator=\"gpu\",\n",
    "    num_nodes=1,\n",
    "    strategy=\"auto\",\n",
    "    # overfit_batches=1,\n",
    "    gradient_clip_val=0.5,\n",
    "    logger=tb_logger,\n",
    "    # check_val_every_n_epoch = 1,\n",
    "    # log_every_n_steps=1\n",
    ")\n",
    "\n",
    "# trainer.fit(model=model, datamodule=datamodule)\n",
    "\n",
    "tuner = Tuner(trainer)\n",
    "# Auto-scale batch size by growing it exponentially (default)\n",
    "# tuner.scale_batch_size(model, datamodule=datamodule, mode=\"power\")\n",
    "\n",
    "# finds learning rate automatically\n",
    "# sets hparams.lr or hparams.learning_rate to that learning rate\n",
    "# Run learning rate finder\n",
    "lr_finder = tuner.lr_find(model, datamodule=datamodule)\n",
    "\n",
    "# Results can be found in\n",
    "# print(lr_finder.results)\n",
    "\n",
    "# Pick point based on plot, or get suggestion\n",
    "new_lr = lr_finder.suggestion()\n",
    "\n",
    "fig = lr_finder.plot(suggest=True)\n",
    "\n",
    "# # update hparams of the model\n",
    "# model.hparams.learning_rate = new_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr_finder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fig \u001b[38;5;241m=\u001b[39m \u001b[43mlr_finder\u001b[49m\u001b[38;5;241m.\u001b[39mplot(suggest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m new_lr \u001b[38;5;241m=\u001b[39m lr_finder\u001b[38;5;241m.\u001b[39msuggestion()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lr_finder' is not defined"
     ]
    }
   ],
   "source": [
    "fig = lr_finder.plot(suggest=True)\n",
    "new_lr = lr_finder.suggestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnew_lr\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_lr' is not defined"
     ]
    }
   ],
   "source": [
    "new_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet101\n",
    "import lightning as L\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class ResNet101Regression(nn.Module):\n",
    "    def __init__(self, num_output_features=1):\n",
    "        super().__init__()\n",
    "        # Load a pre-trained ResNet-50 model\n",
    "        self.resnet = resnet101(weights=None)\n",
    "        # Replace the classifier layer for regression\n",
    "        num_ftrs = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(num_ftrs, num_output_features)\n",
    "        # If your targets are in the range [0, 1], you might want to add a sigmoid layer:\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet101Regression(num_output_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
